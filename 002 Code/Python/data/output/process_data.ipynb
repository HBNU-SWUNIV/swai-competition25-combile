{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "554ebf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Callable\n",
    "from collections import namedtuple\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "import json, os, csv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef9e397",
   "metadata": {},
   "source": [
    "## news_id 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d39b5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = {'N-1-1300101-20250512': 1, \n",
    "        'N-5-1100901-20250512': 2, \n",
    "        'N-4-1300201-20250512': 3, \n",
    "        'error': 4, \n",
    "        'N-2-1100201-20250512': 5, \n",
    "        'N-1-8100401-202505111': 6, \n",
    "        'N-5-4104008-202505112': 7,\n",
    "        'N-4-1200201-202505111': 8, \n",
    "        'N-3-1500601-202505111': 9,\n",
    "        'N-2-1501201-202505111': 10,\n",
    "        'N-1-8100401-20250512': 11,\n",
    "        'N-5-1500401-202505122': 12, \n",
    "        'N-4-1400351-202505122': 13, \n",
    "        'N-3-1300201-20250512': 14, \n",
    "        'N-2-1300201-20250512': 15, \n",
    "        'N-1-8100401-20250511': 16, \n",
    "        'N-5-1400351-20250511': 17, \n",
    "        'N-4-2100101-20250511': 18, \n",
    "        'N-3-8100401-20250511': 19, \n",
    "        'N-2-4101008-20250511': 20, \n",
    "        'error_02': 21, \n",
    "        'N-6-1100611-202505121': 22,\n",
    "        'N-5-1400351-202505122': 23,\n",
    "        'N-4-1100901-20250512': 24, \n",
    "        'N-3-1100801-20250512': 25,\n",
    "        'N-2-2100311-20250512': 26\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74f50cf",
   "metadata": {},
   "source": [
    "## statics.txt 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab8f79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_news_id = {\n",
    "    \"01_News\": 0,\n",
    "    \"02_Domain\" : 2,\n",
    "    \"03_Word\": 5,\n",
    "    \"04_PNComment\": 3,\n",
    "    \"05_Summary\": 3\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "data_type = [\"01_News\", \"02_Domain\", \"03_Word\", \"04_PNComment\", \"05_Summary\"]\n",
    "base_path = Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL\")\n",
    "statistics_save_path = Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/statistics.txt\")\n",
    "\n",
    "for news_id in range(1,27):\n",
    "    data_statistics = {\n",
    "        \"01_News\":0,\n",
    "        \"02_Domain\":0,\n",
    "        \"03_Word\":0,\n",
    "        \"04_PNComment\": 0,\n",
    "        \"05_Summary\":0\n",
    "    }\n",
    "    \n",
    "    for type in data_type:\n",
    "        #데이터 타입별 경로\n",
    "        data_path = base_path / type\n",
    "        \n",
    "        #도메인별 경로 접근\n",
    "        for domain in data_path.glob(\"*.txt\"):\n",
    "            #동일 도메인별 집합\n",
    "            with open(domain, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = f.readlines()\n",
    "                \n",
    "            for record in data:\n",
    "                try:\n",
    "                    record = eval(record.strip(\",\\n\"))\n",
    "                except Exception as e: print(record)\n",
    "                \n",
    "                \n",
    "                if news_id == record[loc_news_id[type]] : data_statistics[type] += 1\n",
    "            # loc_news_id[domain.name] : 아이디 위치\n",
    "            \n",
    "    with open(statistics_save_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        print(f\"news: No.{news_id}\",file=f)\n",
    "        for type, count in data_statistics.items():\n",
    "            print(type, count, file=f)\n",
    "        print(\"-\"*10, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63cfdcb",
   "metadata": {},
   "source": [
    "# news_id 포맷 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9368df89",
   "metadata": {},
   "source": [
    "## news_id 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d1a01e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = {\"01_News\":0, \"02_Domain\":2, \"03_Word\":4, \"04_PNComment\":3, \"05_Summary\":3}\n",
    "\n",
    "for folder in target:\n",
    "    if folder != \"01_News\" : continue\n",
    "    SQL_format = Path(f\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/{folder}\")\n",
    "    \n",
    "    for file in SQL_format.glob(\"*.txt\"):\n",
    "        new_table = []\n",
    "        \n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            table = f.readlines()\n",
    "        \n",
    "        for record in table:\n",
    "            record = list(eval(record.strip(\",\\n\")))\n",
    "            #뉴스 아이디 위치\n",
    "            record[target[folder]] = id_map[record[target[folder]]]\n",
    "            new_table.append(str(tuple(record)))\n",
    "        \n",
    "        with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\",\\n\".join(new_table))\n",
    "            \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ea4ff",
   "metadata": {},
   "source": [
    "# OutputJson_summary id 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdf80e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data/ generate_data에서 반복 실행\n",
    "#경제 1 -\n",
    "domains = \"경제,국제,사회,정치,IT_과학\".split(\",\")\n",
    "num = 1\n",
    "for domain in domains:\n",
    "    summary_data = Path(f\"/Users/minji/Desktop/Test/NewsSummarization/data/generate_data/{domain}/Summary\")\n",
    "    \n",
    "    for summary in summary_data.glob(\"*.json\"):\n",
    "        with open(summary, 'r', encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "        \n",
    "        split_id = json_data[\"summary_id\"].split(\"-\")\n",
    "        split_id[-1] = str(num) ; num+=1\n",
    "        json_data[\"summary_id\"] = \"\".join(split_id)\n",
    "        \n",
    "        with open(summary, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c877d",
   "metadata": {},
   "source": [
    "# SQL 형식 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a18957ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#뉴스데이터 형식 변환\n",
    "NewsData = namedtuple(\"NewsData\", [\"news_id\", \"uuid\", \"title\", \"author\", \"content\", \"views\", \"thumbnail_url\", \"created_at\"])\n",
    "\n",
    "#요약데이터 형식 변환\n",
    "Summary = namedtuple(\"Summary\", [\"summary_id\", \"level\", \"summary_content\", \"news_id\"] )\n",
    "\n",
    "#코멘트 데이터 형식 변환\n",
    "PNComment = namedtuple(\"PNComment\", [\"pn_evaluation_id\", \"positive_comment\", \"negative_comment\", \"news_id\"])\n",
    "\n",
    "#도메인 데이터 형식 변환\n",
    "Domain = namedtuple(\"Domain\", [\"domain_id\",\"domain\",\"news_id\"])\n",
    "\n",
    "#단어 형식 변환\n",
    "Word = namedtuple(\"Word\", [\"word_id\",\"word_definition\",\"sentence\", \"level\", \"news_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44612bf",
   "metadata": {},
   "source": [
    "## csv로 파일 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/01_News\")\n",
    "\n",
    "for domain in base.glob(\"*.txt\"):\n",
    "    with open(domain, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.readlines()\n",
    "        \n",
    "    with open(domain.with_suffix(\".csv\"), \"w\", newline=\"\", encoding=\"utf-8\") as fout:\n",
    "        writer = csv.writer(fout, quoting=csv.QUOTE_ALL)\n",
    "        \n",
    "        for row in data:\n",
    "            record = list(eval(row.rstrip(\",\\n\")))\n",
    "\n",
    "            # 문자열 필드 안의 실제 줄바꿈을 다시 '\\\\n' 문자열로 되돌림\n",
    "            record = [\n",
    "                field.replace(\"\\n\", \"\\\\n\") if isinstance(field, str) else field\n",
    "                for field in record\n",
    "            ]\n",
    "\n",
    "            writer.writerow(record)\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e583c49",
   "metadata": {},
   "source": [
    "## 명령문 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f91b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape_sql(s: str) -> str:\n",
    "    return s.replace(\"'\",\"''\").replace(\"\\n\",\"\\\\n\")\n",
    "\n",
    "base = Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/01_News/csv\")\n",
    "\n",
    "for domain in base.glob(\"*.csv\"):\n",
    "    with open(domain, \"r\", encoding=\"utf-8\") as fin, open(domain.with_suffix(\".sql\"), \"w\", encoding=\"utf-8\" ) as fout:\n",
    "        reader = csv.reader(fin)\n",
    "        \n",
    "        #한 행씩 리딩\n",
    "        for row in reader:\n",
    "            sql_val = []\n",
    "            \n",
    "            for val in row:\n",
    "                if val.lower() == \"nan\":\n",
    "                    sql_val.append(\"NULL\")\n",
    "                elif val.isnumeric() : sql_val.append(val)\n",
    "                else:\n",
    "                    safe = escape_sql(val)\n",
    "                    sql_val.append(f\"'{safe}'\") #이렇게 해야 insert문에 '' 잘 표기 되는 군... \" \"는 파이썬에서 문자열을 작성할때나 그럴 때 필수로 써야하는거고 출력할땐 빼고 나오잖니, 그런 이치 아닐가>\n",
    "            insert_format = f\"INSERT INTO News VALUES ({', '.join(sql_val)});\"\n",
    "            fout.write(insert_format + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163611a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fileds = {\n",
    "    \"Domain\": (\"id\", \"title\", \"content\"),\n",
    "    \"Word\" : (\"word_id\",\"word_definition\",\"sentence\", \"level\", \"news_id\"),\n",
    "    \"PNComment\":(\"pn_evaluation_id\", \"positive_comment\", \"negative_comment\", \"news_id\"),\n",
    "    \"Summary\": (\"summary_id\", \"level\", \"summary_content\", \"news_id\"),\n",
    "        \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "base_path = Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL\")\n",
    "\n",
    "#0으로 시작하는 폴더 찾기\n",
    "for type in base_path.glob(\"0*\"):\n",
    "    type_name = type.name.split(\"_\")[1]\n",
    "    \n",
    "    for domain in type.glob(\"*.txt\"):\n",
    "        with open(domain, \"r\", encoding=\"utf-8\") as fin:\n",
    "            data = f.readlines(f)\n",
    "            table = []\n",
    "            \n",
    "            for record in data:\n",
    "                #python 객체로 변환\n",
    "                record = tuple(eval(record.rstrip(\",\\n\")))\n",
    "                table.append(record)\n",
    "                \n",
    "            insert_format = f\"INSERT INTO {type_name} {fileds[type_name]}VALUES{\",\\n\".join(table)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe995833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_to_double(field: str) -> str:\n",
    "    #따옴표 제외 컨텐츠 섹션만 뽑아옴\n",
    "    match = re.match(r\"^'(.*)'$\", field)\n",
    "    if match:\n",
    "        content = match.group(1).replace('\"','\"\"') #내부 따옴표 처리 \"\"(2번 적어야 함)\n",
    "        return content\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "18a10fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/01_News\")\n",
    "\n",
    "for csv_file in base.glob(\"*.csv\"):\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as fin:\n",
    "        data = csv.reader(fin)\n",
    "        #한 행씩 가져옴   \n",
    "        converted = []\n",
    "        for row in data:\n",
    "            converted = [convert_to_double(field) for field in row]\n",
    "        \n",
    "    with open(csv_file, \"w\", encoding=\"utf-8\", newline=\"\") as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        writer.writerow(converted)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c86fdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trasfer_news(root: Path):\n",
    "    for domain in root.iterdir():\n",
    "        table = []\n",
    "        if domain.name == \"process_data.ipynb\": continue\n",
    "    \n",
    "        for data in domain.glob(\"*.json\"):\n",
    "            with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "                json_data = json.load(f)\n",
    "                \n",
    "            sql_obj = NewsData(\n",
    "                news_id = json_data[\"news_id\"],\n",
    "                uuid = None,\n",
    "                title=json_data[\"title\"],\n",
    "                author=json_data[\"author\"],\n",
    "                content=json_data[\"content\"],\n",
    "                views=0,\n",
    "                thumbnail_url=json_data[\"imageUrl\"],\n",
    "                created_at=json_data[\"creatAt\"][:4]+\"-\"+ json_data[\"creatAt\"][4:6]+\"-\"+json_data[\"creatAt\"][6:]\n",
    "            )\n",
    "            \n",
    "            table.append(str(tuple(sql_obj)))\n",
    "        with open(domain.parent / f\"{domain.name}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\",\\n\".join(table))\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def transfer_word(root: Path):\n",
    "    table = []\n",
    "    for domain in root.iterdir():\n",
    "        if domain.name.startswith(\".\"): continue\n",
    "        words = Path(f\"/Users/minji/Desktop/Test/NewsSummarization/data/generate_data/{domain.name}/Word\")\n",
    "        \n",
    "        for file in words.iterdir():\n",
    "            if file.name.startswith(\".\") : continue\n",
    "            \n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            for word in json_data:\n",
    "                sql_obj = Word(\n",
    "                    word_id= word[\"word\"],\n",
    "                    word_definition=word[\"definition\"],\n",
    "                    sentence=word[\"sentence\"],\n",
    "                    level=word[\"level\"],\n",
    "                    news_id=word[\"newsId\"]\n",
    "                )\n",
    "                \n",
    "                table.append(str(tuple(sql_obj)))      \n",
    "        save_path = Path(f\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/03_Word/{domain.name}.txt\")\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\",\\n\".join(table))\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def transfer_domain():\n",
    "    domains = \"경제,국제,사회,정치,IT_과학\".split(\",\") ; cnt = 1\n",
    "    #도메인 id 매핑정보\n",
    "    domain_id = {\n",
    "        \"경제\": \"1\",\n",
    "        \"국제\" : \"2\",\n",
    "        \"사회\" : \"3\",\n",
    "        \"정치\" : \"4\",\n",
    "        \"IT_과학\" : \"5\"\n",
    "    }\n",
    "    \n",
    "    save_root = Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/02_Domain\")\n",
    "    \n",
    "    for domain in domains:\n",
    "        table = []\n",
    "        with open(Path(f\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/01_News/{domain}.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = f.readlines()\n",
    "        \n",
    "        for news in data:\n",
    "            news_tuple = eval(news.strip(\",\\n\"))\n",
    "            id = news_tuple[0] #뉴스 id 추출\n",
    "        \n",
    "            save_format = (domain_id[domain], domain, id)\n",
    "            table.append(str(save_format))\n",
    "\n",
    "        with open(save_root / f\"{domain}.txt\" , \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\",\\n\".join(table))\n",
    "    \n",
    "    return\n",
    "    \n",
    "def transfer_pn_evaluation():\n",
    "    for domain in Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/generate_data\").iterdir():\n",
    "        table = []\n",
    "        if domain.name.startswith(\".\") : continue\n",
    "        comments = Path(f\"/Users/minji/Desktop/Test/NewsSummarization/data/generate_data/{domain.name}/Comment\")\n",
    "        \n",
    "        for comment in comments.glob(\"*.json\"):\n",
    "            with open(comment, \"r\", encoding=\"utf-8\") as f:\n",
    "                json_obj = json.load(f)\n",
    "            \n",
    "            sql_obj = PNComment(\n",
    "                pn_evaluation_id = json_obj[\"pnEvaluationId\"],\n",
    "                positive_comment= json_obj[\"positiveComment\"],\n",
    "                negative_comment=json_obj[\"negativeComment\"],\n",
    "                news_id=json_obj[\"newsId\"]\n",
    "                \n",
    "            )\n",
    "            table.append(str(tuple(sql_obj)))\n",
    "\n",
    "        with open(Path(f\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/04_PNComment/{domain.name}.txt\"),\n",
    "                \"w\",\n",
    "                encoding=\"utf-8\") as f:\n",
    "            \n",
    "            f.write(\",\\n\".join(table))\n",
    "    return\n",
    "\n",
    "def transfer_summary(root: Path):\n",
    "    table = []\n",
    "    for domain in root.iterdir():\n",
    "        if (domain.name == \".DS_Store\") : continue\n",
    "\n",
    "        for type in domain.iterdir():\n",
    "            if (type.name == \"Comment\") or (type.name == \".DS_Store\") : continue\n",
    "            \n",
    "            for summary in type.glob(\"*.json\"):\n",
    "                with open(summary, \"r\", encoding=\"utf-8\") as f:\n",
    "                    json_data = json.load(f)\n",
    "                    \n",
    "                sql_obj = Summary(\n",
    "                    summary_id = json_data[\"summary_id\"],\n",
    "                    level=json_data[\"level\"],\n",
    "                    summary_content=json_data[\"summaryContent\"],\n",
    "                    news_id=json_data[\"newsId\"]\n",
    "                )\n",
    "                \n",
    "                table.append(str(tuple(sql_obj)))\n",
    "        \n",
    "        with open(domain.parent / f\"{domain.name}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\",\\n\".join(table))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0c2c262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_word= Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/03_Word\") ; c_cnt = 1\n",
    "\n",
    "\n",
    "for domain in root_word.glob(\"*.txt\"):\n",
    "    new_table = [] ; \n",
    "    \n",
    "    with open(domain, \"r\", encoding=\"utf-8\") as f:\n",
    "        table = f.readlines()\n",
    "        \n",
    "    for record in table:\n",
    "        record = list(eval(record.strip(\",\\n\")))\n",
    "        record.insert(0,c_cnt) ; c_cnt += 1\n",
    "        \n",
    "        new_table.append(str(tuple(record)))\n",
    "        \n",
    "    with open(domain, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\",\\n\".join(new_table))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0c5b7d",
   "metadata": {},
   "source": [
    "## News 테이블 uuid 주입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "31a5f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "root = Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/SQL/01_News\")\n",
    "\n",
    "for domain in root.glob(\"*.txt\"):\n",
    "    matrix = []\n",
    "    \n",
    "    with open(domain, \"r\", encoding=\"utf-8\") as f:\n",
    "        table = f.readlines()\n",
    "        \n",
    "    for row in table:\n",
    "        record = list(eval(row.strip(\",\\n\"), {\"UUID\": uuid.UUID}))\n",
    "        record[1] = str(uuid.uuid4())#uuid 생성\n",
    "        matrix.append(str(tuple(record)))\n",
    "        \n",
    "    with open(domain, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\",\\n\".join(matrix))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1dc98",
   "metadata": {},
   "source": [
    "# Word생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f2d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "using_model = \"gpt-4o\"\n",
    "\n",
    "\n",
    "def create_word(level: str, data):\n",
    "    def decorator(func: Callable):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            word_prompt =  f\"\"\"\n",
    "            당신은 텍스트 전문 AI 어시스턴트입니다. 당신은 주어진 텍스트에 대하여 사용자의 어휘력 수준에 따라서 특정 단어 사전적 정의와 예문을 제시하여야합니다.\n",
    "            우리는 {data[\"content\"]}에서 3개의 단어를 추출합니다. 아래의 규칙을 따라주세요.\n",
    "\n",
    "            1. 사용자의 어휘 수준은 \"{level}\"입니다.\n",
    "            2. \"Low\" 수준일 경우: 일반인이 어려워할 고급 어휘를 중심으로 선정하세요.\n",
    "            3. \"High\" 수준일 경우: 전문 용어나 도메인 지식을 포함한 단어를 중심으로 선정하세요.\n",
    "            3.  출력 형식은 {word_template}형식에 맞게 json으로 제공합니다.\n",
    "            4. newsId에는 {data[\"news_id\"]} 값을 입력합니다.\n",
    "            \"\"\"\n",
    "            return func(word_prompt)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "def generate(word_prompt):\n",
    "    response = client.chat.completions.create (\n",
    "        model = using_model,\n",
    "        messages = [\n",
    "            {\"role\": \"user\",\n",
    "            \"content\" : word_prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "73bd11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/output\")\n",
    "save_path = Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/generate_data\")\n",
    "cnt = 1\n",
    "for domain in root.iterdir():\n",
    "    if domain.name == \".DS_Store\" or domain.name == \"process_data.ipynb\": continue\n",
    "    \n",
    "    for data in domain.iterdir():\n",
    "        if data.name == \".DS_Store\" : continue\n",
    "        \n",
    "        with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        for level in [\"Low\", \"High\"]:\n",
    "            decorate_func = create_word(level,data)(generate)\n",
    "            result = decorate_func()\n",
    "            save_dir = save_path / domain.name / \"Word\"\n",
    "            if not save_dir.exists() : save_dir.mkdir(parents=True, exist_ok=True)\n",
    "            file_name = f\"OutputJson_word_{level}_{cnt}.txt\"\n",
    "            \n",
    "            with open(save_dir / file_name , \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(result)\n",
    "            \n",
    "        cnt += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc8033",
   "metadata": {},
   "source": [
    "# 정규식으로 코드블록 마커 지우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for domain in Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/generate_data\").iterdir():\n",
    "    if not domain.is_dir(): continue\n",
    "    path = Path(f\"/Users/minji/Desktop/Test/NewsSummarization/data/generate_data/{domain.name}/Word\")\n",
    "    \n",
    "    for file in path.iterdir():\n",
    "        if file.name == \".DS_Store\": continue\n",
    "        \n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = f.read()\n",
    "        \n",
    "        cleaned = re.sub(r'^```(json)?\\s*$', '', data, flags=re.MULTILINE)\n",
    "        # 문자열을 JSON으로 변환\n",
    "        json_obj = json.loads(cleaned)\n",
    "        \n",
    "        #확장자 변환\n",
    "        with open(file.with_suffix(\".json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(json_obj, f, ensure_ascii=False, indent=4)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "76f3e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain in Path(\"/Users/minji/Desktop/Test/NewsSummarization/data/generate_data\").iterdir():\n",
    "    if not domain.is_dir(): continue\n",
    "    path = Path(f\"/Users/minji/Desktop/Test/NewsSummarization/data/generate_data/{domain.name}/Word\")\n",
    "    \n",
    "    for file in path.iterdir():\n",
    "        if file.name.startswith == \".\": continue\n",
    "        \n",
    "        if file.suffix == \".txt\" or \"txt\" in file.name : file.unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
